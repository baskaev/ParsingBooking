import time
import random
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
from urllib.parse import urljoin

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Selenium
def get_driver():
    options = Options()
    # options.add_argument('--headless')  # <=== –£–î–ê–õ–ò –≠–¢–£ –°–¢–†–û–ö–£!
    options.add_argument('--disable-gpu')
    options.add_argument('--no-sandbox')
    options.add_argument('--start-maximized')  # –æ—Ç–∫—Ä—ã–≤–∞—Ç—å –Ω–∞ –≤–µ—Å—å —ç–∫—Ä–∞–Ω
    return webdriver.Chrome(options=options)


# –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Ç–µ–ª—è
def download_hotel_page(url):
    driver = get_driver()
    try:
        driver.get(url)
        time.sleep(5)  # –ñ–¥—ë–º –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        html = driver.page_source
        return html
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {e}")
        return None
    finally:
        driver.quit()


def parse_hotel_page(html_content):
    soup = BeautifulSoup(html_content, 'html.parser')

    result = {
        'name': '',
        'address': '',
        'score': '',
        'score_text': '',
        'description': '',
        'surroundings': [],
        'restaurants': [],
        'attractions': [],
        'beaches': [],
        'transport': [],
        'airports': [],
        'facilities': [],
        'house_rules': {},
        'important_notes': [],
        'rooms': []  # <== –î–û–ë–ê–í–õ–ï–ù–û
    }

    # –ù–∞–∑–≤–∞–Ω–∏–µ –æ—Ç–µ–ª—è
    name_tag = soup.find('h2', class_='d2fee87262')
    if name_tag:
        result['name'] = name_tag.get_text(strip=True)

    # –ê–¥—Ä–µ—Å
    address_tag = soup.find('span', class_='hp_address_subtitle')
    if address_tag:
        result['address'] = address_tag.get_text(strip=True)

    # –û—Ü–µ–Ω–∫–∞
    score_tag = soup.find('div', class_='b5cd09854e')
    if score_tag:
        result['score'] = score_tag.get_text(strip=True)

    # –¢–µ–∫—Å—Ç–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
    score_text_tag = soup.find('div', class_='d8eab2cf7f')
    if score_text_tag:
        result['score_text'] = score_text_tag.get_text(strip=True)

    # –û–ø–∏—Å–∞–Ω–∏–µ
    desc_div = soup.find('div', {'data-capla-component-boundary': 'b-property-web-property-page/PropertyDescriptionDesktop'})
    if desc_div:
        desc_p = desc_div.find('p', {'data-testid': 'property-description'})
        if desc_p:
            result['description'] = desc_p.get_text(strip=True)

    # –û–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç–∏
    poi_blocks = soup.find_all('div', {'data-testid': 'poi-block'})
    for block in poi_blocks:
        title_div = block.find('div', class_='e7addce19e')
        if title_div:
            title = title_div.get_text(strip=True)
            items = []
            for li in block.find_all('li', class_='b0bf4dc58f'):
                name_div = li.find('div', class_='aa225776f2')
                distance_div = li.find('div', class_='b99b6ef58f')
                if name_div and distance_div:
                    items.append({
                        'name': name_div.get_text(strip=True),
                        'distance': distance_div.get_text(strip=True)
                    })

            if title == '–í –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç—è—Ö':
                result['surroundings'] = items
            elif title == '–†–µ—Å—Ç–æ—Ä–∞–Ω—ã –∏ –∫–∞—Ñ–µ':
                result['restaurants'] = items
            elif title == '–ì–ª–∞–≤–Ω—ã–µ –¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏':
                result['attractions'] = items
            elif title == '–ü–ª—è–∂–∏ –≤ –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç—è—Ö':
                result['beaches'] = items
            elif title == '–û–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç':
                result['transport'] = items
            elif title == '–ë–ª–∏–∂–∞–π—à–∏–µ –∞—ç—Ä–æ–ø–æ—Ä—Ç—ã':
                result['airports'] = items

    # –£–¥–æ–±—Å—Ç–≤–∞
    facility_groups = soup.find_all('div', {'data-testid': 'facility-group-container'})
    for group in facility_groups:
        title_div = group.find('div', class_='e7addce19e')
        if title_div:
            title = title_div.get_text(strip=True)
            facilities = []
            for li in group.find_all('li', class_='b0bf4dc58f'):
                facility_span = li.find('span', class_='f6b6d2a959')
                if facility_span:
                    facilities.append(facility_span.get_text(strip=True))
            result['facilities'].append({
                'group': title,
                'items': facilities
            })

    # –£—Å–ª–æ–≤–∏—è —Ä–∞–∑–º–µ—â–µ–Ω–∏—è
    rules_section = soup.find('section', id='policies')
    if rules_section:
        rule_blocks = rules_section.find_all('div', class_='b0400e5749')
        for block in rule_blocks:
            title_div = block.find('div', class_='e7addce19e')
            content_div = block.find('div', class_='b99b6ef58f')
            if title_div and content_div:
                result['house_rules'][title_div.get_text(strip=True)] = content_div.get_text(strip=True)

    # –í–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    notes_section = soup.find('section', id='important_info')
    if notes_section:
        notes_div = notes_section.find('div', class_='c85a1d1c49')
        if notes_div:
            for p in notes_div.find_all('p'):
                text = p.get_text(strip=True)
                if text:
                    result['important_notes'].append(text)

    # üõè –ù–æ–º–µ—Ä–∞ (–∫–æ–º–Ω–∞—Ç—ã)
    room_blocks = soup.find_all('div', {'data-testid': 'roomloop-block'})
    for room in room_blocks:
        room_data = {}

        # –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–Ω–∞—Ç—ã
        title_tag = room.find('div', class_='c667c82436')
        if title_tag:
            room_data['title'] = title_tag.get_text(strip=True)

        # –¶–µ–Ω–∞
        price_tag = room.find('span', class_='f6431b446c fbfd7c1165')
        if price_tag:
            room_data['price'] = price_tag.get_text(strip=True)

        # –£—Å–ª–æ–≤–∏—è –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        condition_tag = room.find('span', class_='db63693c62')
        if condition_tag:
            room_data['conditions'] = condition_tag.get_text(strip=True)

        if room_data:
            result['rooms'].append(room_data)

    return result


# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ –æ—Ç–µ–ª–∏ (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π)
def get_hotel_links(search_url):
    driver = get_driver()
    try:
        driver.get(search_url)
        time.sleep(5)
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        hotel_links = []
        for link in soup.find_all('a', {'data-testid': 'title-link'}):
            href = link.get('href')
            if href and 'hotel' in href:
                hotel_links.append(urljoin('https://www.booking.com', href))
        return list(set(hotel_links))
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫: {e}")
        return []
    finally:
        driver.quit()

# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def scrape_and_save_hotels(search_url, output_file='hotels_data.xlsx'):
    hotel_links = get_hotel_links(search_url)
    if not hotel_links:
        print("–°—Å—ã–ª–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        return

    all_data = []

    for i, link in enumerate(hotel_links, 1):
        print(f"[{i}/{len(hotel_links)}] –ó–∞–≥—Ä—É–∂–∞—é: {link}")
        html = download_hotel_page(link)
        if not html:
            continue
        data = parse_hotel_page(html)
        data['url'] = link
        all_data.append(data)
        time.sleep(random.uniform(1, 2.5))

    df = pd.json_normalize(all_data)
    df.to_excel(output_file, index=False)
    print(f"\n‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ —Ñ–∞–π–ª: {output_file}")

# –ü—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å–∫–∞
if __name__ == '__main__':
    search_url = "https://www.booking.com/searchresults.ru.html?ss=–ë–∞—Ä—Å–µ–ª–æ–Ω–∞"
    scrape_and_save_hotels(search_url)
